{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agastya1995/Market-Basket-Analysis/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-zyPjmIO5b9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Embedding, Dense, Input, Reshape, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend  \n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPfkUsPJO5cH"
      },
      "source": [
        "train = pd.read_csv('DNN Data on Healthcare Analytics_Train.csv')\n",
        "test = pd.read_csv('DNN Data on Healthcare Analytics_Test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vlc5lid6O5cT"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss0WzMsgO5cd"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoHDAFboO5ck"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1EPtyj6O5cv"
      },
      "source": [
        "**See which variables are categorical variables and which are numeric** \n",
        "**Categorical Variables:**\n",
        "1. Hospital Code\n",
        "2. Hospital Type Code\n",
        "3. City Code Hospital\n",
        "4. Hospital Region Code (Drop?)\n",
        "5. Department\n",
        "6. Ward Type\n",
        "7. Ward Code\n",
        "9. Patient ID (Can be dropped)\n",
        "10. City_Code_Patient (Can be dropped)\n",
        "11. Type of Admission\n",
        "12. Severity of Illness (Has order, so label encode)\n",
        "13. Age (Label encode)\n",
        "14. Stay (Convert to separate class - Label Encode for now)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJyRVJAjO5cx"
      },
      "source": [
        "def convert_target(length_of_stay):\n",
        "    if length_of_stay in ['0-10', '11-20']:\n",
        "        return 1\n",
        "    elif length_of_stay in ['21-30', '31-40']:\n",
        "        return 2\n",
        "    elif length_of_stay in ['41-50', '51-60']:\n",
        "        return 3\n",
        "    elif length_of_stay in ['61-70', '71-80']:\n",
        "        return 4\n",
        "    else:\n",
        "        return 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX10LMpiO5c5"
      },
      "source": [
        "def preprocess(df):\n",
        "    # Drop nas\n",
        "    df.dropna(inplace=True)\n",
        "    # Drop columns that are not needed\n",
        "    df = df.sample(frac=1)\n",
        "    target = df['Stay']\n",
        "    df = df.drop(['patientid', 'City_Code_Patient', 'Stay'], axis=1)\n",
        "    \n",
        "    \n",
        "    # Since there is an order to severity of illness, manually map the integers to it\n",
        "    df['Severity of Illness'] = df['Severity of Illness'].map(lambda x: 0 if x=='Minor' else 1 if x=='Moderate' else 2)\n",
        "    # Take age as the mid point\n",
        "    df['Age'] = df['Age'].map(lambda x: int(x.split('-')[0])+4)\n",
        "    \n",
        "    # Label encode all the other cateogrical columns \n",
        "    cat_cols = df.columns[df.dtypes=='object']\n",
        "    for i in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "        df[i] =  le.fit_transform(df[i])\n",
        "        \n",
        "    # Normalize the other columns\n",
        "    non_cat_columns = [i for i in df.columns if i not in cat_cols]\n",
        "    min_max = MinMaxScaler()\n",
        "    df[non_cat_columns] = min_max.fit_transform(df[non_cat_columns])\n",
        "    \n",
        "    # Convert the 11 classes in target to 5 \n",
        "    target_converted = target.map(convert_target)\n",
        "        \n",
        "    # Make dummies\n",
        "    target_converted = pd.get_dummies(target_converted)\n",
        "    \n",
        "    return (df, cat_cols, target_converted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_SnzXEvO5c-"
      },
      "source": [
        "train, cat_cols, train_target = preprocess(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxZrJffPO5dC"
      },
      "source": [
        "train_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByz-ovNO5dK"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lysLXSSJO5dS"
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keq34XBFO5dY"
      },
      "source": [
        "### Embedding ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJbX0MhFO5da"
      },
      "source": [
        "backend.clear_session()\n",
        "models = []\n",
        "inputs = []\n",
        "\n",
        "for feature in cat_cols:\n",
        "    number_of_unique_cat = train[feature].nunique()\n",
        "    embedding_size = int(np.ceil(number_of_unique_cat/2))\n",
        "    input_layer = Input(shape=1)\n",
        "    embedding_layer = Embedding(number_of_unique_cat+1, embedding_size, input_length=1)(input_layer)\n",
        "    output_layer = Reshape((embedding_size,))(embedding_layer)\n",
        "    models.append(output_layer)\n",
        "    inputs.append(input_layer)\n",
        "\n",
        "input_rest = Input(shape=8)\n",
        "output_rest = Dense(32)(input_rest)\n",
        "models.append(output_rest)\n",
        "inputs.append(input_rest)\n",
        "\n",
        "full_model = concatenate(models)\n",
        "x1 = Dense(32, activation = 'relu')(full_model)\n",
        "x1 = Dense(64, activation = 'relu')(x1)\n",
        "\n",
        "output = Dense(5, activation='softmax')(x1)\n",
        "final_model = Model(inputs, output)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_8S1ohqO5di"
      },
      "source": [
        "def Convert_Df_To_List(df, cat_cols):\n",
        "    train_set_for_model = [df[i].values for i in cat_cols]\n",
        "    train_set_for_model.append(df.loc[:, ~df.columns.isin(cat_cols)])\n",
        "    return train_set_for_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgo5-a5eO5dn"
      },
      "source": [
        "final_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwqUgJVZO5ds"
      },
      "source": [
        "# Convert dataframe to list\n",
        "train_set_for_model = Convert_Df_To_List(train, cat_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqQC_-y5O5dz"
      },
      "source": [
        "len(train_set_for_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xigBypplO5d4"
      },
      "source": [
        "final_model.compile(loss='categorical_crossentropy', metrics=['accuracy', tfa.metrics.CohenKappa(num_classes=5)])\n",
        "hist = final_model.fit(x=train_set_for_model, y=train_target.values, batch_size=128, epochs=50, validation_split=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrxk2J_4O5d8"
      },
      "source": [
        "test, _, test_target = preprocess(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2aXihcpO5eA"
      },
      "source": [
        "test_for_model = Convert_Df_To_List(test, cat_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9oA_I46O5eG"
      },
      "source": [
        "test_for_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKq2ug99O5eQ"
      },
      "source": [
        "preds = final_model.predict(test_for_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqYOz0E0QwIx"
      },
      "source": [
        "cohen_kappa = tfa.metrics.CohenKappa(5, sparse_labels=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h--LgTBaRLLQ"
      },
      "source": [
        "preds_t = preds.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsFIHIfORb_t"
      },
      "source": [
        "actual_t = np.argmax(test_target.values, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ6SI6D9Q199"
      },
      "source": [
        "cohen_kappa.update_state(preds_t, actual_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLnlE2k1Txw-"
      },
      "source": [
        "cohen_kappa.result().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TSBP_U1a1jx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}